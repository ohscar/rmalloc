.. vim:tw=120

.. raw:: latex

    \chapter{Steve: The Benchmark Tool
        \label{chapter-steve}}

Steve is a benchmark tool for collecting and visualizing runtime memory access and allocation patterns in arbitrary binary
applications that use the system malloc, without access to source code or recompilation, and performing tests without
running the actual application.

.. figure:: graphics/steve.png
   :scale: 50%

   :label:`steve-overview` Architectural diagram of Steve

Multiple statistics files can be fed to the grapher for doing comparisons between different allocators on the same input
data set.

Tools
=====
Steve is a collection of tools:

* ``translate-memtrace-to-ops.py``
* ``translate-ops-to-histogram.py``
* ``translate-ops-to-locking-lifetime.py``
* ``run_allocator_stats.sh``, ``run_allocator_stats_payload.sh``
* ``run_memory_frag_animation.sh``
* ``run_graphs_from_allocstats.py``
* ``run_memory_frag_animation_plot_animation.py``

For a detailed description, see the appendix.


Allocator Driver Usage
===================================
Steve does, in essense, two tasks: visualize memory and plot benchmark data. The framework allows for fairly easy
extension with more tools.

* ``run_memory_frag_animation.sh``: create an animated memory allocation visualisation.
* ``run_graphs_from_allocstats.py``:  create benchmark based on one or many allocator statistics inputs
  (generated by ``run_allocator_stats.sh``)

The tools are described in more detail in the next section.

All alloc drivers are linked to the same main program and have the same command line parameters:

* ``--peakmem opsfile``
    
    Prints out therotical heap size allocated as reported by the allocator driver. ``--allocstats`` passes this data to
    benchmark data files for later processing by the graphing tool.

    Parameters:

    - opsfile - operations file created by ``translate-memtrace-to-ops.py``.

* ``--allocstats opsfile resultfile killpercent oplimit peakmemsize theoretical_heap_size``

    Generates a file in JSON format in the following format. Header::

        driver = "jemalloc"
        opsfile = "result.program-ops"
        heap_size = 13544700
        theoretical_heap_size = 4514900
        opmode = 'allocstats'
        alloc_stats = [

    Then, per line a dictionary with the following keys::

        {'op_index':        <sequene number>,
         'free':            <bytes: integer>,
         'used':            <bytes: integer>,
         'overhead':        <bytes: integer>,
         'maxmem':          <bytes: integer>,
         'current_op_time': <microseconds: integer>,
         'oom_time':        <microsecond: integer>,
         'optime_maxmem':   <microsecond: integer>,
         'op':              <operation <- N, F, A, L, U: char>,
         'size':            <bytes: integer>
        }
    
    Parameters:

    - opsfile: Operations file created by ``translate-memtrace-to-ops.py``.
    - resultfile: Statistics output file, convention is to use file stem of opsfile (without "-ops") and append
      "-allocstats"
    - killpercent: Optionally rewind and randomly free *killpercent* (0-100) of all headers at EOF, to simulate an application that destroys and creates new documents. The value 100'000 means no rewinding or killing takes place, i.e. just one round of the data gathered by running the application to be benchmarked.
    - oplimit: Which operation ID (*0..total ops count*) to write alloctaion stats for. The special value 0 is for writing the original header.
      Typically the driver application is called in a for loop from 0 to the number of operations, i.e. number of lines
      in the opsfile.

* ``--memplot opsfile [heap_size]``

    For each operation, call out ``run_memory_frag_animation_plot_animation.py`` to create a PNG of the heap at that
    point in time.  The driver application only needs to be run once.

    .. Also creates output similar to ``--allocstats``. (TODO: deprecate this!)

    Parameters:

    - opsfile - operations file created by ``translate-memtrace-to-ops.py``.
    - (optional) heap_size - maximum heap size to use


These are not called directly, but instead called from by the tools described below.

At startup the mode of operation of the allocator driver is set to one of these. All modes perform follow the same basic
flow:

#. Allocate heap according to specified heap size or use predefined size (currently 1 GB).
   If heap allocation fails, decrease by 10% until success.
#. Allocate and initialize colormap as :math:`\frac{1}{4}` of heap size. (more on colormap later)
#. Initialize driver.
#. Initialize randomness with compile-time set seed.
#. Open opsfile.
#. Run mode's main loop.
#. Save statistics created by mode's main loop.
#. Destroy driver.

The main loop follows the same basic structure:

#. Scan a line of the ops file and put in the variables handle, *op*, *address* and *size*.
#. Switch on op:

   - Op is N (New): Call ``user_malloc`` with the size. On OOM, call ``user_handle_oom`` and call ``user_malloc`` again if
     successfully handled. Make sure that there was no OOM on the final malloc. Retrieve the highest address in use by
     ``user_highest_address``. Store object pointer (that may or may not be a directly accessible memory address) and
     memory address (if available) from malloc along with size in maps keyed on the handle id.
   - Op is F (Free): Retrieve the object pointer and call ``user_free``.
   - Op is L (Lock): Retreive the object pointer and all ``user_lock``.
   - Op is U (Unlock): Retreive the object pointer and all ``user_unlock``.

   Access (load, store, modify) operations are not handled in the loop since their use is limited to calculating
   lifetime statistics and locking behaviour.

#. Exit on EOF.

Driver Modes
=============
In this section, I'll describe the specifics on the three main loops (peakmem, allocstats, memplot) and then the tools that use them.

peakmem
~~~~~~~~~~~~~
Find the largest amount of memory during the driver's lifetime for a specific opsfile, as calculated by the highest
address+size of a block minus the start address of the heap. This number is used as a theoretical maximum heap size to
mesaure the amount of overhead. 

Used by the tool ``run_allocator_stats.sh``. 

allocstats
~~~~~~~~~~~~~~~~~~~~~~~~~~
Adds rewinding of the input file and random free of a certain percentage, if requested, of the allocated objects on opsfile EOF. The
purpose is to allow for the driver application to run several rounds of the application data, as explained above, to do
a rough simulation of an application creating and destroying documents.
It augments new and free with the time the operation takes and stores information about the operation in a list for
later processing.

Used by the tool ``run_allocator_stats.sh``.

memplot
~~~~~~~~~~~~~~~~~~~~~~~~~~
Also adds non-optional rewinding to run until OOM. At each operation, a *colormap* is updated with all known objects. In
order to retrieve the physical memory address they are locked (throuh ``user_lock``) and the pointer is registered.

Colormap is 25% of the heap size, such that each 4-byte word maps onto a byte. The colormap is initially filled with
white (for overhead), with a new operation painted as red and free painted as green. The heap is corresondingly filled
with ``HEAP_INITIAL`` (``0xDEADBEEF``) initially, and newly created blocks are filled with ``HEAP_ALLOC`` (``0xBEEFBABE``) and
blocks that are just about to be freed are filled with ``HEAP_FREE`` (``0xDEADBABE``).

Now, by scanning the heap for values that are not in the set ``HEAP_INITIAL``, ``HEAP_ALLOC`` nor ``HEAP_FREE``, it can
be concluded that this is overhead (i.e. allocator-internal structures). Paint the corresponding memory location in the
colormap with white (for overhead).

Tested Allocators
=================================
The allocator often used by Linux and elsewhere in the open-source world is Doug Lea's Malloc *dlmalloc*, that performs
well in the average case. For FreeBSD, Poul-Henning Kamp wrote an allocator that he aptly named *pkhmalloc*. *dlmalloc*
aims to be good enough for most single-threaded use cases and is well-documented, therefore attractive to anyone in need
of an allocator.  It does not perform optimally in multi-threaded applications because of the coarse (operation-level)
locking.  Other allocators are designed to be used in a mutli-threaded application where locking is performed on a finer
level, not blocking other threads trying to use the allocator at the same time.

In fact, at Opera, *dlmalloc* was used internally to better tune allocator characteristics for memory-constrained
devices, where all available memory was requested at startup and then used by the internal malloc.

The allocators tested are drop-in replacements for malloc and free. Including garbage collectors in this test is left
for future work.

rmmalloc (Jeff)
~~~~~~~~~~~~~~~~~~~~~
Maps all ``user_...`` calls to the corresponding calls in Jeff. For the compacting version, ``user_handle_oom`` always performs a full compact, and on the non-compacting version, ``user_handle_oom`` is a no-op.

The workings of Jeff is described earlier in this paper.

jemalloc (v1.162 2008/02/06)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*jemalloc* is an allocator written by Jason Evans, originally written for a custom development environment circa 2005, later
integrated into FreeBSD for its multi-threading capabilities and later further adapted in 2007 for use by the Firefox
project to deal with fragmentation issues. It's since been adapted for heavy-duty use in the Facebook servers [#]_.
As of 2010, it still performs better than the system-provided allocators in MacOS, Windows and Linux. [#]_ 

.. [#] https://github.com/jemalloc/jemalloc/wiki/History
.. [#] http://www.quora.com/Who-wrote-jemalloc-and-what-motivated-its-creation-and-implementation

.. TODO: fill in more information about *jemalloc*: goal, design

Alloc and free calls mapped to the corresponding function call. Handle OOM is a no-op. Configured to use sbrk (``opt_dss
= true``), but not mmap (``opt_mmap = false``).

dlmalloc v2.8.6
~~~~~~~~~~~~~~~~~~~~~~
*dlmalloc* is an allocator written by Doug Lea and is used by the GNU standard C library, glibc.  The source code states
the following about its goal:
    
    This is not the fastest, most space-conserving, most portable, or most tunable malloc ever written. However it is
    among the fastest while also being among the most space-conserving, portable and tunable.  Consistent balance across
    these factors results in a good general-purpose allocator for malloc-intensive programs.

.. TODO: fill in more information about *dlmalloc*: goal, design

Alloc and free calls mapped to the corresponding function call. Handle OOM is a no-op. Configured to use sbrk but not
mmap.

tcmalloc (gperftools-2.1)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
gperftools [#]_ is written by Google and includes a profiling/benchmark framework/tools. It is used by, among others,
Google Chrome, MySQL and WebKit Fang (2012), which in turn is used by many other projects such
as Apple's Safari. It includes the allocator *tcmalloc*.

.. [#] http://code.google.com/p/gperftools/

.. TODO: fill in more information about tcmalloc: goal, design

Alloc and free calls mapped to the corresponding function call. Handle OOM is a no-op. Configured to use sbrk but not
mmap.


